{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a2a594",
   "metadata": {},
   "source": [
    "# Fase 6\n",
    "## Estrategia detallada paso a paso (qu√© hacer antes de entrenar)\n",
    "\n",
    "### 2.1 Pre-filtrado estructural \n",
    "- Eliminar columnas con >30‚Äì40% de valores nulos (NaN) o imputar si son relevantes.  \n",
    "- Eliminar columnas con varianza casi nula (constantes).  \n",
    "- Detectar y eliminar duplicados exactos o altamente correlacionados.  \n",
    "- Convertir precios a **retornos logar√≠tmicos** y mantener precios si aportan contexto adicional.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2 Priorizaci√≥n por dominio\n",
    "Seleccionar manualmente variables relevantes por grupo:\n",
    "\n",
    "- **Acciones bancarias:** precios, volumen, retornos, volatilidades m√≥viles (30d).  \n",
    "- **√çndices:** IBEX, S&P500, DAX ‚Äî retornos + volatilidades m√≥viles.  \n",
    "- **Divisas (FX):** EURUSD, EURBRL ‚Äî retornos o niveles seg√∫n correlaci√≥n.  \n",
    "- **Commodities:** petr√≥leo, oro ‚Äî retornos o niveles seg√∫n relaci√≥n con el mercado.  \n",
    "- **Macroecon√≥micos:** PIB, IPC, tipos BCE ‚Äî incluir rezagos (lags) temporales.  \n",
    "- **Eventos:** impacto cuantificado (`Impact_Score` o similar).\n",
    "\n",
    "üëâ Idea: mantener **3‚Äì8 variables por grupo** para conservar representatividad sin sobrecargar el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3 Selecci√≥n estad√≠stica autom√°tica (complementaria)\n",
    "Aplicar m√©todos autom√°ticos sobre el conjunto de entrenamiento:\n",
    "\n",
    "- **Correlaci√≥n con el target:** `corrwith(BBVA_Close)` o `corrwith(SANT_Close)` sobre retornos; mantener top N (p.ej. 50).  \n",
    "- **VarianceThreshold:** eliminar columnas con varianza baja.  \n",
    "- **Multicolinealidad:** eliminar features con alto VIF (Variance Inflation Factor).  \n",
    "- **Importancia (√°rboles):** usar RandomForest o GradientBoost r√°pido para priorizar las m√°s influyentes.\n",
    "\n",
    "‚ö†Ô∏è Importante: **filtrar siempre usando solo el conjunto de entrenamiento**, nunca con test.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4 Reducci√≥n de dimensionalidad\n",
    "Opciones recomendadas:\n",
    "\n",
    "- **PCA:** escalar datos y elegir componentes que expliquen 80‚Äì95% de la varianza (‚âà10‚Äì50 componentes).  \n",
    "- **Autoencoder:** alternativa no lineal que puede capturar relaciones complejas.  \n",
    "- **Agregaci√≥n / clustering:** promediar o sintetizar variables muy similares.  \n",
    "- **H√≠brido:** combinar top features seleccionadas + PCA sobre el resto.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5 Recomendaciones num√©ricas\n",
    "- N√∫mero final de variables:  \n",
    "  - Interpretables: **30‚Äì60 features**.  \n",
    "  - Compactas (post-PCA/AE): **10‚Äì30 componentes**.  \n",
    "- Si el modelo predice m√∫ltiples outputs (BBVA, SANT), mantener suficiente diversidad (‚âà50 features).  \n",
    "- Ajustar n√∫mero seg√∫n longitud de ventana temporal (60‚Äì120 d√≠as ‚Üí m√°s features = m√°s memoria).\n",
    "\n",
    "---\n",
    "\n",
    "### 2.6 Otros puntos clave\n",
    "- **Imputaci√≥n:** aplicar antes de PCA; `forward-fill` o medianas para macro.  \n",
    "- **Escalado:** `StandardScaler` o `RobustScaler`, ajustado solo con train.  \n",
    "- **Lags:** crear lags relevantes (1, 3, 7, 30 d√≠as) para macro y FX.  \n",
    "- **Pruebas controladas:**  \n",
    "  - Baseline (pocas features manuales).  \n",
    "  - Variante top-50.  \n",
    "  - Variante PCA-20.  \n",
    "  - Comparar rendimiento y coste.\n",
    "\n",
    "---\n",
    "\n",
    "### Checklist r√°pido (FASE 6)\n",
    "- [ ] Eliminar columnas con >30% NaN  \n",
    "- [ ] Eliminar columnas con varianza nula  \n",
    "- [ ] Calcular retornos y volatilidades m√≥viles  \n",
    "- [ ] Seleccionar top 50 correlaciones  \n",
    "- [ ] Aplicar PCA/AE a resto y fijar n√∫mero de componentes  \n",
    "- [ ] Guardar lista final de variables (`final_features_list.csv`)  \n",
    "- [ ] Documentar transformaciones (scalers, imputers, PCA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215ad63",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "## Resumen del flujo recomendado antes del modelado RNN\n",
    "\n",
    "### 1. Limpieza estructural\n",
    "- Eliminar columnas con m√°s de 30‚Äì40% de valores nulos.  \n",
    "- Eliminar columnas constantes o duplicadas.  \n",
    "- Imputar los valores faltantes restantes (`forward-fill`, media o mediana seg√∫n el caso).  \n",
    "- Escalar todas las variables (`StandardScaler` o `RobustScaler`).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Transformaciones de mercado\n",
    "- Convertir precios a **retornos logar√≠tmicos**:  \n",
    "  \\[\n",
    "  r_t = \\log\\left(\\frac{P_t}{P_{t-1}}\\right)\n",
    "  \\]\n",
    "- Calcular **volatilidades m√≥viles** (rolling std) de 30 y 90 d√≠as para capturar din√°mica temporal.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Selecci√≥n de variables relevantes\n",
    "- Calcular la **correlaci√≥n en valor absoluto** de todas las variables con los **retornos de BBVA y Santander**.  \n",
    "- Seleccionar las **Top N** (por ejemplo 50‚Äì80) variables m√°s correlacionadas.  \n",
    "- Este subconjunto representa las features m√°s informativas para el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Reducci√≥n de dimensionalidad (PCA)\n",
    "- Aplicar **PCA** sobre las variables restantes (no seleccionadas en el paso anterior).  \n",
    "- Conservar las componentes que expliquen entre **90‚Äì95% de la varianza total** (‚âà10‚Äì30 componentes).  \n",
    "- Combinar:\n",
    "  - Las variables seleccionadas por correlaci√≥n.  \n",
    "  - Las componentes principales del PCA.\n",
    "\n",
    "üì¶ **Resultado:**  \n",
    "Un dataset limpio, compacto y optimizado con unas **~60 variables finales**, que combinan la relevancia estad√≠stica (correlaci√≥n) y la representaci√≥n comprimida (PCA), ideal para la siguiente fase de modelado RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa1442f",
   "metadata": {},
   "source": [
    "## Libreries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0498bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82fb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "007ca095",
   "metadata": {},
   "source": [
    "## 1. Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c3d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# üßπ FASE 6.1 ‚Äî LIMPIEZA INICIAL (optimizada con NumPy)\n",
    "# ============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================\n",
    "# CONFIG\n",
    "# ============================\n",
    "DATA_PATH = Path(\"../../data/processed/data.csv.gz\")\n",
    "\n",
    "# ============================\n",
    "# CARGA\n",
    "# ============================\n",
    "\n",
    "data = pd.read_csv(\n",
    "    DATA_PATH,\n",
    "    compression=\"gzip\",\n",
    "    parse_dates=[\"Date\"],\n",
    "    index_col=\"Date\",\n",
    "    dtype=float  # convierte todas las columnas a float directo\n",
    ")\n",
    "print(f\"Dataset cargado con {data.shape[0]} filas y {data.shape[1]} columnas.\")\n",
    "display(data.head())\n",
    "\n",
    "# ============================\n",
    "# 1Ô∏è‚É£ Conversi√≥n de tipos\n",
    "# ============================\n",
    "for col in data.select_dtypes(include='object').columns:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae07d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 2Ô∏è‚É£ Eliminaci√≥n de columnas duplicadas exactas\n",
    "# ============================\n",
    "data = data.loc[:, ~data.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b571b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 3Ô∏è‚É£ Eliminaci√≥n de columnas altamente correlacionadas (>0.98) usando NumPy\n",
    "# ============================\n",
    "# Convertir a numpy array\n",
    "arr = data.to_numpy()\n",
    "# Calcular correlaci√≥n\n",
    "corr_matrix = np.corrcoef(arr, rowvar=False)\n",
    "# Mantener la matriz superior triangular\n",
    "upper_tri = np.triu(corr_matrix, k=1)\n",
    "\n",
    "# Columnas a eliminar\n",
    "to_drop = [data.columns[i] for i in range(len(data.columns)) if any(upper_tri[:, i] > 0.98)]\n",
    "print(f\"Columnas eliminadas por alta correlaci√≥n: {len(to_drop)}\")\n",
    "\n",
    "# Eliminar columnas\n",
    "data = data.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 4Ô∏è‚É£ Comprobaciones finales\n",
    "# ============================\n",
    "print(f\"Dataset limpio ‚Üí {data.shape[0]} filas y {data.shape[1]} columnas.\")\n",
    "print(f\"Nulos restantes: {data.isna().sum().sum()}\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230972ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 5Ô∏è‚É£ Guardar dataset limpio temporal\n",
    "# ============================\n",
    "output_path = Path(\"../../data/processed/data_clean.csv.gz\")\n",
    "data.to_csv(output_path, compression=\"gzip\")\n",
    "print(f\"‚úÖ Dataset limpio guardado en: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
